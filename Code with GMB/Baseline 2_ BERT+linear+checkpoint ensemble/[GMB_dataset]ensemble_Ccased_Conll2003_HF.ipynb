{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[GMB_dataset]ensemble_Ccased_Conll2003_HF.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e9c31bf6d5a0484b86cf3c364351673a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c717ca4eb1dc472f9569a2e3f79cefdd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_61703a06cbb54016b56fd39326674fbd","IPY_MODEL_2ec118e9cab142cb8b6f9d07ad0552b5","IPY_MODEL_1591f6a8a53649f89a76433e7a11d8d7"]}},"c717ca4eb1dc472f9569a2e3f79cefdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61703a06cbb54016b56fd39326674fbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_088d4f56bc0e43848f117e6339af7405","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56d5eac802af4093ae9ba2dfde10cd66"}},"2ec118e9cab142cb8b6f9d07ad0552b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_40232d26a318437faacb0cf142d22cec","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d6c27e8d4b0e4c7aa9dbd1e009261c03"}},"1591f6a8a53649f89a76433e7a11d8d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d75768a64eee4a3faaf15ef365200a68","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 208k/208k [00:00&lt;00:00, 370kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef9f77c14b484f84bb0480d540f96697"}},"088d4f56bc0e43848f117e6339af7405":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"56d5eac802af4093ae9ba2dfde10cd66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40232d26a318437faacb0cf142d22cec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d6c27e8d4b0e4c7aa9dbd1e009261c03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d75768a64eee4a3faaf15ef365200a68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ef9f77c14b484f84bb0480d540f96697":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef6dee8196284514bb0d5f6d922358f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_499c067f498b4b94bf5dd88b6ae9ac84","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d8676299acb640b9949d0a83c05c833b","IPY_MODEL_0d39c7c167ea4b7490cd240c8872c1ea","IPY_MODEL_a4afcee6510a4ff781b207541004313a"]}},"499c067f498b4b94bf5dd88b6ae9ac84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8676299acb640b9949d0a83c05c833b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0883bbe5cc6d4617aa5c35bea3974f91","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b06bb4ffbe842b18097de49b777d74c"}},"0d39c7c167ea4b7490cd240c8872c1ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_47c1f0da3907408ea88fe21f0e442253","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435797,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435797,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33e0085885d3425db386dfa1554182e6"}},"a4afcee6510a4ff781b207541004313a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b2102b28c9334af7b18d66d194407c78","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 426k/426k [00:00&lt;00:00, 790kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8debdd5e4f6c4ca683e2659a6c70c66c"}},"0883bbe5cc6d4617aa5c35bea3974f91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4b06bb4ffbe842b18097de49b777d74c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47c1f0da3907408ea88fe21f0e442253":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"33e0085885d3425db386dfa1554182e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2102b28c9334af7b18d66d194407c78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8debdd5e4f6c4ca683e2659a6c70c66c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c148e136b2e4c6abfc1de345861e159":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2f65d8e7f5d44d9e9383d4d35d7f3a24","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_634f6849a65c4abea1aad5575188eb5f","IPY_MODEL_f71b4481b29e4fcbaead1d630ee60a10","IPY_MODEL_23c4d28d0df74371805bd582f3e80abb"]}},"2f65d8e7f5d44d9e9383d4d35d7f3a24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"634f6849a65c4abea1aad5575188eb5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_662730125d2b4cfabce0134848962c2b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6738ef50c1e34796ab2c232a72019c6c"}},"f71b4481b29e4fcbaead1d630ee60a10":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_170f731a51f54cc9ba92bb039c0f9604","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_722d5a9b61444a99b8c9428e507ce27e"}},"23c4d28d0df74371805bd582f3e80abb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_38d8239f15a34f62ae450aa9e6b63a3d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 648B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23fb8b72071d4568acc2fe2d3befecbd"}},"662730125d2b4cfabce0134848962c2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6738ef50c1e34796ab2c232a72019c6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"170f731a51f54cc9ba92bb039c0f9604":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"722d5a9b61444a99b8c9428e507ce27e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38d8239f15a34f62ae450aa9e6b63a3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"23fb8b72071d4568acc2fe2d3befecbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb00a5d4cf5e49bcbf9c11629aff8bc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5e9976e74fa147fb94740dc733451fed","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_118f99b21a704ccda54c6f989bac6122","IPY_MODEL_265d6a4f611e4fa285c8daed5b594639","IPY_MODEL_60b639399ef64d9c8fbdbdb4c5aa138f"]}},"5e9976e74fa147fb94740dc733451fed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"118f99b21a704ccda54c6f989bac6122":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_55c77533636f4466b029ec31a03b79b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46b36d974d904ef4a6ec613eae038b81"}},"265d6a4f611e4fa285c8daed5b594639":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a210c5234e504652aa85d6207c5a393b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e83d3d6398e44d091199a2e07a09a06"}},"60b639399ef64d9c8fbdbdb4c5aa138f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_21bc927bcbd14e3c9b4d3f5bd1a30f79","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 14.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcb0d9190da6409185f02108be45f23e"}},"55c77533636f4466b029ec31a03b79b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46b36d974d904ef4a6ec613eae038b81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a210c5234e504652aa85d6207c5a393b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5e83d3d6398e44d091199a2e07a09a06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21bc927bcbd14e3c9b4d3f5bd1a30f79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bcb0d9190da6409185f02108be45f23e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5bda3537e17f41f4a9c23daade6cbcb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0f115527b8342e1aec7c089a0063650","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0c2d7b3a7d8241ff880222e663323875","IPY_MODEL_c644f7b68a3a4db197ddde528d998e96","IPY_MODEL_2721c1285fe34d19b839fbaa20f58902"]}},"a0f115527b8342e1aec7c089a0063650":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c2d7b3a7d8241ff880222e663323875":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71d9e68fc87c404fa6ad0cd1653b4be4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c1c230963d2d4f848459cd917c96cc4a"}},"c644f7b68a3a4db197ddde528d998e96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2ac90f52f41049bcbbf948334ff3f1bf","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435779157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435779157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be0d575de19249338ede7439353e73e2"}},"2721c1285fe34d19b839fbaa20f58902":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70a0b8cbb8414d8aa20f045a812508b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 416M/416M [00:14&lt;00:00, 32.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e84e4e0e9294433bd439dd92efa88ce"}},"71d9e68fc87c404fa6ad0cd1653b4be4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c1c230963d2d4f848459cd917c96cc4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ac90f52f41049bcbbf948334ff3f1bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"be0d575de19249338ede7439353e73e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70a0b8cbb8414d8aa20f045a812508b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e84e4e0e9294433bd439dd92efa88ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DR6WnnwSiiPx"},"source":["## **1. Find the corresponding positive values for NER, POS, Chunk tags**"]},{"cell_type":"markdown","metadata":{"id":"2UELiLBQjpy0"},"source":["Ref: https://github.com/huggingface/datasets/blob/master/datasets/conll2003/conll2003.py"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gk0Tt5rrrWkF","executionInfo":{"status":"ok","timestamp":1639030941294,"user_tz":-480,"elapsed":18029,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"b44c7e8e-2780-42df-8905-3824900cfd73"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"wNF30bg7jgaO"},"source":["# **2. Data Preprocessing for BERT Model (Apply Hugging Face Data)**"]},{"cell_type":"markdown","metadata":{"id":"_Hrzhmg_fyDG"},"source":["Ref:https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb\n","Ref:https://huggingface.co/transformers/glossary.html\n"]},{"cell_type":"markdown","metadata":{"id":"5BMn0-NQnkOV"},"source":["### (1) Hugging Face Dataset Conll2003 Exploration"]},{"cell_type":"code","metadata":{"id":"ZIPMjy9KBFAX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639030955385,"user_tz":-480,"elapsed":9538,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"d695cf61-2b23-4e1c-a1bb-d25297834a79"},"source":["!pip install datasets"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 92 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 122 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 133 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 143 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 153 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 163 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 174 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 184 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 194 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 204 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 215 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 225 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 235 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 245 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 256 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 266 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 276 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 286 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 296 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 298 kB 13.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 47.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 474 kB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 52.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 39.9 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 48.7 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n","\u001b[K     |████████████████████████████████| 192 kB 51.4 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 50.8 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, huggingface-hub, datasets\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 datasets-1.16.1 frozenlist-1.2.0 fsspec-2021.11.1 huggingface-hub-0.2.1 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n"]}]},{"cell_type":"code","metadata":{"id":"htUmCUrUBS0D","executionInfo":{"status":"ok","timestamp":1639030974966,"user_tz":-480,"elapsed":7146,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}}},"source":["from datasets import load_dataset\n","# dataset = load_dataset('conll2003')"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IXOdIATZoNVQ"},"source":["### (2) Covert Data to BERT Input Style"]},{"cell_type":"code","metadata":{"id":"IsEmtyyeniqn","colab":{"base_uri":"https://localhost:8080/","height":922},"executionInfo":{"status":"ok","timestamp":1639030990241,"user_tz":-480,"elapsed":10653,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"36c39f3b-5ce1-4d6c-f066-86144deae4af"},"source":["!pip install transformers seqeval[gpu]"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 13.4 MB/s \n","\u001b[?25hCollecting seqeval[gpu]\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 43.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 42.6 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 53.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval[gpu]) (1.0.1)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.0.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=0fdb26b33ca19668a7821547df07fa20a4aefe2e85e658460b16b2960e75b5b7\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: pyyaml, tokenizers, seqeval, sacremoses, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-6.0 sacremoses-0.0.46 seqeval-1.2.2 tokenizers-0.10.3 transformers-4.12.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"mUG0I8A-ndPo","executionInfo":{"status":"ok","timestamp":1639030996303,"user_tz":-480,"elapsed":3299,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3QG7H7OW4sT","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["e9c31bf6d5a0484b86cf3c364351673a","c717ca4eb1dc472f9569a2e3f79cefdd","61703a06cbb54016b56fd39326674fbd","2ec118e9cab142cb8b6f9d07ad0552b5","1591f6a8a53649f89a76433e7a11d8d7","088d4f56bc0e43848f117e6339af7405","56d5eac802af4093ae9ba2dfde10cd66","40232d26a318437faacb0cf142d22cec","d6c27e8d4b0e4c7aa9dbd1e009261c03","d75768a64eee4a3faaf15ef365200a68","ef9f77c14b484f84bb0480d540f96697","ef6dee8196284514bb0d5f6d922358f1","499c067f498b4b94bf5dd88b6ae9ac84","d8676299acb640b9949d0a83c05c833b","0d39c7c167ea4b7490cd240c8872c1ea","a4afcee6510a4ff781b207541004313a","0883bbe5cc6d4617aa5c35bea3974f91","4b06bb4ffbe842b18097de49b777d74c","47c1f0da3907408ea88fe21f0e442253","33e0085885d3425db386dfa1554182e6","b2102b28c9334af7b18d66d194407c78","8debdd5e4f6c4ca683e2659a6c70c66c","5c148e136b2e4c6abfc1de345861e159","2f65d8e7f5d44d9e9383d4d35d7f3a24","634f6849a65c4abea1aad5575188eb5f","f71b4481b29e4fcbaead1d630ee60a10","23c4d28d0df74371805bd582f3e80abb","662730125d2b4cfabce0134848962c2b","6738ef50c1e34796ab2c232a72019c6c","170f731a51f54cc9ba92bb039c0f9604","722d5a9b61444a99b8c9428e507ce27e","38d8239f15a34f62ae450aa9e6b63a3d","23fb8b72071d4568acc2fe2d3befecbd","cb00a5d4cf5e49bcbf9c11629aff8bc1","5e9976e74fa147fb94740dc733451fed","118f99b21a704ccda54c6f989bac6122","265d6a4f611e4fa285c8daed5b594639","60b639399ef64d9c8fbdbdb4c5aa138f","55c77533636f4466b029ec31a03b79b6","46b36d974d904ef4a6ec613eae038b81","a210c5234e504652aa85d6207c5a393b","5e83d3d6398e44d091199a2e07a09a06","21bc927bcbd14e3c9b4d3f5bd1a30f79","bcb0d9190da6409185f02108be45f23e"]},"executionInfo":{"status":"ok","timestamp":1639031010994,"user_tz":-480,"elapsed":5152,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"2283fc96-48d3-4404-a088-1250acc3a1b7"},"source":["MAX_LEN = 128     \n","TRAIN_BATCH_SIZE = 4\n","TEST_BATCH_SIZE = 2\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9c31bf6d5a0484b86cf3c364351673a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef6dee8196284514bb0d5f6d922358f1","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c148e136b2e4c6abfc1de345861e159","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb00a5d4cf5e49bcbf9c11629aff8bc1","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","source":["data = pd.read_csv(\"/content/drive/MyDrive/NLP/New Dataset/Bank/ner_datasetreference.csv\", encoding='unicode_escape')\n","data.head()\n","\n","data.count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NIRZycPIriYe","executionInfo":{"status":"ok","timestamp":1639031028756,"user_tz":-480,"elapsed":3705,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"74d8dc1a-f231-4264-e353-5e5dd69a52df"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sentence #      47959\n","Word          1048575\n","POS           1048575\n","Tag           1048575\n","dtype: int64"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["'''\n","step 2a: process NE tags and POS tags\n","'''\n","# NE \n","\"\"\"There are 8 category tags, each with a \"beginning\" and \"inside\" variant, and the \"outside\" tag. It is not really clear what these tags mean - \"geo\" probably stands for geographical entity, \"gpe\" for geopolitical entity, and so on. They do not seem to correspond with what the publisher says on Kaggle. Some tags seem to be underrepresented. Let's print them by frequency (highest to lowest): \"\"\"\n","\n","# tags = {}\n","# for tag, count in zip(frequencies_NE.index, frequencies_NE):\n","#     if tag != \"O\":\n","#         if tag[2:5] not in tags.keys():\n","#             tags[tag[2:5]] = count\n","#         else:\n","#             tags[tag[2:5]] += count\n","#     continue\n","\n","# print(sorted(tags.items(), key=lambda x: x[1], reverse=True))\n","\n","\"\"\"Let's remove \"art\", \"eve\" and \"nat\" named entities, as performance on them will probably be not comparable to the other named entities. \"\"\"\n","\n","entities_to_remove = [\"B-art\", \"I-art\", \"B-eve\", \"I-eve\", \"B-nat\", \"I-nat\"]\n","data = data[~data.Tag.isin(entities_to_remove)]\n","data.head()\n","data.count()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ib-HhCr_riV6","executionInfo":{"status":"ok","timestamp":1639031042856,"user_tz":-480,"elapsed":516,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"99f26bbb-8c63-4748-ed27-91c63a59d939"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sentence #      47920\n","Word          1047063\n","POS           1047063\n","Tag           1047063\n","dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["\"\"\"We create 2 dictionaries for NE: one that maps individual tags to indices, and one that maps indices to their individual tags. This is necessary in order to create the labels (as computers work with numbers = indices, rather than words = tags) - see further in this notebook.\"\"\"\n","\n","labels_to_ids = {k: v for v, k in enumerate(data.Tag.unique())}\n","ids_to_labels = {v: k for v, k in enumerate(data.Tag.unique())}\n","print(labels_to_ids)\n","print(ids_to_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsQ2DvPHriTT","executionInfo":{"status":"ok","timestamp":1639031045844,"user_tz":-480,"elapsed":347,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"c7bd8454-bc1a-4a8f-ff09-58895550def7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["{'O': 0, 'B-geo': 1, 'B-gpe': 2, 'B-per': 3, 'I-geo': 4, 'B-org': 5, 'I-org': 6, 'B-tim': 7, 'I-per': 8, 'I-gpe': 9, 'I-tim': 10}\n","{0: 'O', 1: 'B-geo', 2: 'B-gpe', 3: 'B-per', 4: 'I-geo', 5: 'B-org', 6: 'I-org', 7: 'B-tim', 8: 'I-per', 9: 'I-gpe', 10: 'I-tim'}\n"]}]},{"cell_type":"code","source":["# count NE tag\n","print(\"Number of NE tags: {}\".format(len(data.Tag.unique()))) # 17个\n","frequencies_NE = data.Tag.value_counts()\n","frequencies_NE\n","Ner_Tag = list(data.Tag.unique())\n","Ner_Number = [i for i in range(len(Ner_Tag))]\n","Ner = list(zip(Ner_Tag,Ner_Number))\n","print(Ner)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-W6isoYFriQo","executionInfo":{"status":"ok","timestamp":1639031048819,"user_tz":-480,"elapsed":509,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"4ffd3d2a-18fd-4bd2-d12a-cbadb61a4d2d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of NE tags: 11\n","[('O', 0), ('B-geo', 1), ('B-gpe', 2), ('B-per', 3), ('I-geo', 4), ('B-org', 5), ('I-org', 6), ('B-tim', 7), ('I-per', 8), ('I-gpe', 9), ('I-tim', 10)]\n"]}]},{"cell_type":"code","source":["# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n","data = data.fillna(method='ffill')\n","data.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"kmAcflS7riNu","executionInfo":{"status":"ok","timestamp":1639031051349,"user_tz":-480,"elapsed":519,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"a28cc362-db07-470b-8611-cf0dcb24afdf"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 1</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 1</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 1</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1  Sentence: 1             of   IN   O\n","2  Sentence: 1  demonstrators  NNS   O\n","3  Sentence: 1           have  VBP   O\n","4  Sentence: 1        marched  VBN   O"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# let's create a new column called \"sentence\" which groups the words by sentence \n","data['sentence'] = data[['Sentence #','Word','Tag', 'POS']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n","# let's also create a new column called \"word_labels\" which groups the tags by sentence \n","data['word_labels'] = data[['Sentence #','Word','Tag', 'POS']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n","data.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"V0tFt7C4riK0","executionInfo":{"status":"ok","timestamp":1639031162424,"user_tz":-480,"elapsed":97231,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"0d6ceafe-1c67-4610-b7d3-15424c6420fc"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","      <th>sentence</th>\n","      <th>word_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 1</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 1</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 1</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Sentence #  ...                                        word_labels\n","0  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","1  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","2  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","3  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","4  Sentence: 1  ...  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...\n","\n","[5 rows x 6 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["\"\"\"Let's only keep the \"sentence\" and \"word_labels\" columns, and drop duplicates:\"\"\"\n","\n","data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n","data.head()\n","\n","len(data)\n","\"\"\"Let's verify that a random sentence and its corresponding tags are correct:\"\"\"\n","\n","print(data.iloc[41].sentence)\n","print(data.iloc[41].word_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mEgB626riIL","executionInfo":{"status":"ok","timestamp":1639031274218,"user_tz":-480,"elapsed":856,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"0f4befbe-74f7-4d89-a550-1cf2be90ab9b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Bedfordshire police said Tuesday that Omar Khayam was arrested in Bedford for breaching the conditions of his parole .\n","B-gpe,O,O,B-tim,O,B-per,I-per,O,O,O,B-geo,O,O,O,O,O,O,O,O\n"]}]},{"cell_type":"code","source":["train_df, validate_df, test_df = \\\n","              np.split(data.sample(frac=1, random_state=42), \n","                       [int(.85*len(data)), int(.925*len(data))])\n"],"metadata":{"id":"QsWiFaqgriFd","executionInfo":{"status":"ok","timestamp":1639031276910,"user_tz":-480,"elapsed":2,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train_df = train_df.reset_index(drop=True)\n","validate_df = validate_df.reset_index(drop=True)\n","test_df = test_df.reset_index(drop=True)\n","\n","data_combine_dict = {'train':train_df, 'validation':validate_df, 'test':test_df}\n"],"metadata":{"id":"J9OIRVZ0riC8","executionInfo":{"status":"ok","timestamp":1639031279517,"user_tz":-480,"elapsed":536,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"blADhhnVBS44","executionInfo":{"status":"ok","timestamp":1639031282010,"user_tz":-480,"elapsed":459,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}}},"source":["class Preprocess_Data(Dataset):\n","  def __init__(self, dataset, tokenizer, max_len, usage): #usage -> train, validation, test\n","\n","        self.len = len(dataset[usage])\n","        self.data = dataset[usage]\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","  def __getitem__(self, index):\n","\n","        # step 1: get the sentence and word labels \n","        sentence = self.data['sentence'][index].strip().split()\n","        word_labels = self.data['word_labels'][index].split(\",\")\n","\n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                              is_split_into_words=True,\n","                              return_offsets_mapping=True,  #Set to True to return (char_start, char_end) for each token (default False)\n","                              padding='max_length', \n","                              truncation=True, \n","                              max_length=self.max_len)\n","        \n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","\n","        labels = [labels_to_ids[label] for label in word_labels]\n","\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","          if mapping[0] == 0 and mapping[1] != 0:\n","            # overwrite label\n","            encoded_labels[idx] = labels[i]\n","            i += 1\n","\n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['labels'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQ54suiDDxHD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639031284845,"user_tz":-480,"elapsed":336,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"29732624-77f0-4c6c-8265-916e8a3053b4"},"source":["training_set = Preprocess_Data(data_combine_dict, tokenizer, MAX_LEN, 'train')\n","validation_set = Preprocess_Data(data_combine_dict, tokenizer, MAX_LEN, 'validation')\n","testing_set = Preprocess_Data(data_combine_dict, tokenizer, MAX_LEN, 'test')\n","print(len(training_set),len(validation_set),len(testing_set))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["40435 3568 3568\n"]}]},{"cell_type":"code","metadata":{"id":"XKEiV4E4ePuY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639031286659,"user_tz":-480,"elapsed":3,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"cf3d2942-79ba-4980-fced-6db416ea5379"},"source":["training_set[0]"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'input_ids': tensor([  101,  1109, 12046,  6170,  2301,  1150, 12209,  1425,   118,  1385,\n","          6551,  1104,  3519,  1105, 15745,  1144,  2065,  1344,   118, 13395,\n","           117,  4577,  1103,  3294,  6477, 10588,  1555,   119,   102,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]),\n"," 'labels': tensor([-100,    0,    2,    0,    0,    0,    0,    0, -100, -100,    0,    0,\n","            0,    0,    0,    0,    0,    0, -100, -100,    0,    0,    0,    0,\n","            0, -100,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100]),\n"," 'offset_mapping': tensor([[ 0,  0],\n","         [ 0,  3],\n","         [ 0,  7],\n","         [ 0,  9],\n","         [ 0,  6],\n","         [ 0,  3],\n","         [ 0,  7],\n","         [ 0,  3],\n","         [ 3,  4],\n","         [ 4,  7],\n","         [ 0, 10],\n","         [ 0,  2],\n","         [ 0,  5],\n","         [ 0,  3],\n","         [ 0,  9],\n","         [ 0,  3],\n","         [ 0,  4],\n","         [ 0,  4],\n","         [ 4,  5],\n","         [ 5,  9],\n","         [ 0,  1],\n","         [ 0,  7],\n","         [ 0,  3],\n","         [ 0,  6],\n","         [ 0,  4],\n","         [ 4,  9],\n","         [ 0,  7],\n","         [ 0,  1],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0]]),\n"," 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0])}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"w_QFc14DHEWH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639031289508,"user_tz":-480,"elapsed":503,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"0a1098e5-1e9d-4bf5-d87b-4318d1100dea"},"source":["#Verify the encoding result\n","for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n","  print('{0:10}  {1}'.format(token, label))"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS]       -100\n","The         0\n","Tibetan     2\n","spiritual   0\n","leader      0\n","who         0\n","teaches     0\n","age         0\n","-           -100\n","old         -100\n","principles  0\n","of          0\n","peace       0\n","and         0\n","tolerance   0\n","has         0\n","gone        0\n","high        0\n","-           -100\n","tech        -100\n",",           0\n","joining     0\n","the         0\n","online      0\n","mess        0\n","##aging     -100\n","service     0\n",".           0\n","[SEP]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n","[PAD]       -100\n"]}]},{"cell_type":"code","metadata":{"id":"niW9J7uhIBxY","executionInfo":{"status":"ok","timestamp":1639031292616,"user_tz":-480,"elapsed":519,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}}},"source":["# Define the Dataloader\n","training_loader = DataLoader(training_set, batch_size = TRAIN_BATCH_SIZE, shuffle=True,num_workers=0)\n","validation_loader = DataLoader(validation_set,batch_size = TRAIN_BATCH_SIZE, shuffle=True,num_workers=0)\n","testing_loader = DataLoader(testing_set,batch_size = TEST_BATCH_SIZE, shuffle=True,num_workers=0)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6X7rxuYMy6_z"},"source":[""]},{"cell_type":"code","metadata":{"id":"GlaCRzzmIBzz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639031294578,"user_tz":-480,"elapsed":2,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"093530f8-cafc-4371-8abe-b291b6cafb01"},"source":["print(len(training_loader),len(validation_loader),len(testing_loader))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["10109 892 1784\n"]}]},{"cell_type":"markdown","metadata":{"id":"6hF-6klfKomd"},"source":["# **3. Define the Model**"]},{"cell_type":"markdown","metadata":{"id":"t1BNYr_cfPV-"},"source":["Ref:https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb\n","Ref:https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification"]},{"cell_type":"markdown","metadata":{"id":"IKXls9ALdeJt"},"source":["### 1) Train the Model"]},{"cell_type":"code","metadata":{"id":"ndNwQePxFFdY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639031296893,"user_tz":-480,"elapsed":368,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"99b1dabe-42f8-46ab-da02-b07f1cf267e9"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Dec  9 06:28:17 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   64C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LvvmRHQMH2g","executionInfo":{"status":"ok","timestamp":1639031300019,"user_tz":-480,"elapsed":415,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"6c44620b-8031-4371-b06f-c03c58ff2ca2"},"source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(device)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","metadata":{"id":"VCEY_Fb2a7Hm","executionInfo":{"status":"ok","timestamp":1639031302642,"user_tz":-480,"elapsed":417,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}}},"source":["EPOCHS = 3\n","LEARNING_RATE = 1e-05\n","MAX_GRAD_NORM = 10"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8vCJCAFLWgK","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5bda3537e17f41f4a9c23daade6cbcb0","a0f115527b8342e1aec7c089a0063650","0c2d7b3a7d8241ff880222e663323875","c644f7b68a3a4db197ddde528d998e96","2721c1285fe34d19b839fbaa20f58902","71d9e68fc87c404fa6ad0cd1653b4be4","c1c230963d2d4f848459cd917c96cc4a","2ac90f52f41049bcbbf948334ff3f1bf","be0d575de19249338ede7439353e73e2","70a0b8cbb8414d8aa20f045a812508b6","2e84e4e0e9294433bd439dd92efa88ce"]},"executionInfo":{"status":"ok","timestamp":1639031334882,"user_tz":-480,"elapsed":29869,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"b2d73589-e5ba-4d46-80a5-0c352b52a871"},"source":["# Define the model by just BertForTokenClassification\n","model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(Ner_Tag))\n","model.to(device)"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5bda3537e17f41f4a9c23daade6cbcb0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"blREmCNMPgpY","executionInfo":{"status":"ok","timestamp":1639031408596,"user_tz":-480,"elapsed":508,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}}},"source":["optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"t3800AVERAin","executionInfo":{"status":"ok","timestamp":1639031411428,"user_tz":-480,"elapsed":366,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}}},"source":["\n","def train(model,epoch):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","\n","        # if idx >200:\n","        #   break\n","        \n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n","        loss = outputs[0]\n","        tr_logits = outputs[1]\n","\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")\n","\n","    # --------------------------------------------------------------------------------------------------------------------\n","    # After the completion of each training epoch\n","    # measure our performance on validation set.\n","\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(validation_loader):\n","\n","            # if idx >200:\n","            #   break\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            outputs= model(input_ids=ids, attention_mask=mask, labels=labels)\n","            loss = outputs[0]\n","            eval_logits = outputs[1]\n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            if idx % 100==0:\n","                loss_step = eval_loss/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n","              \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYynGVa0aUYt","executionInfo":{"status":"ok","timestamp":1639031415306,"user_tz":-480,"elapsed":494,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"d6b7a9aa-d5a4-49c2-a560-5ab783c1707d"},"source":["len(training_loader),len(validation_loader),len(testing_loader)"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10109, 892, 1784)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"t3ehY9wnXJeC","executionInfo":{"status":"error","timestamp":1639033477047,"user_tz":-480,"elapsed":2047157,"user":{"displayName":"小奶狗喵喵喵","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmHTG3dLKL5_0225w0WN8SnieInLh9QpUxa-Dd=s64","userId":"07360018702871445192"}},"outputId":"14cea6b0-ba67-44bd-87ec-f4067b6d385f"},"source":["for epoch in range(EPOCHS):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    train(model,epoch)\n","    torch.save(model.state_dict(), '/content/drive/MyDrive/baseline_checkpoint/model_weights_'+str(epoch+1)+'.pth')"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.602559804916382\n","Training loss per 100 training steps: 0.7944493205240457\n","Training loss per 100 training steps: 0.5691408508675015\n","Training loss per 100 training steps: 0.4462754127888188\n","Training loss per 100 training steps: 0.3839075167215153\n","Training loss per 100 training steps: 0.3396138603280404\n","Training loss per 100 training steps: 0.31003481850412345\n","Training loss per 100 training steps: 0.2875792362970352\n","Training loss per 100 training steps: 0.26768539347726567\n","Training loss per 100 training steps: 0.2530151368092981\n","Training loss per 100 training steps: 0.24185562075546513\n","Training loss per 100 training steps: 0.23143573203119877\n","Training loss per 100 training steps: 0.22477695722207364\n","Training loss per 100 training steps: 0.2169183257446094\n","Training loss per 100 training steps: 0.20985506741206383\n","Training loss per 100 training steps: 0.20478215566132066\n","Training loss per 100 training steps: 0.20042452177348116\n","Training loss per 100 training steps: 0.1970186786344773\n","Training loss per 100 training steps: 0.19354334737221787\n","Training loss per 100 training steps: 0.18944583452837752\n","Training loss per 100 training steps: 0.1859284889706732\n","Training loss per 100 training steps: 0.18309815728344087\n","Training loss per 100 training steps: 0.18015594183283687\n","Training loss per 100 training steps: 0.17710258496606698\n","Training loss per 100 training steps: 0.17422803813564058\n","Training loss per 100 training steps: 0.17147293315557274\n","Training loss per 100 training steps: 0.16914457593982204\n","Training loss per 100 training steps: 0.16710607032050226\n","Training loss per 100 training steps: 0.1651206367675904\n","Training loss per 100 training steps: 0.1628333296664849\n","Training loss per 100 training steps: 0.16136621264345144\n","Training loss per 100 training steps: 0.15965088741979672\n","Training loss per 100 training steps: 0.1584161504250199\n","Training loss per 100 training steps: 0.15725543293702735\n","Training loss per 100 training steps: 0.15589102717921285\n","Training loss per 100 training steps: 0.1547649183995693\n","Training loss per 100 training steps: 0.15319825420915198\n","Training loss per 100 training steps: 0.1518757793755049\n","Training loss per 100 training steps: 0.15050283153085647\n","Training loss per 100 training steps: 0.14922306459329993\n","Training loss per 100 training steps: 0.1481308735548841\n","Training loss per 100 training steps: 0.14693564197997355\n","Training loss per 100 training steps: 0.14601324217169975\n","Training loss per 100 training steps: 0.14488742526546897\n","Training loss per 100 training steps: 0.14415995610362692\n","Training loss per 100 training steps: 0.1428286474340305\n","Training loss per 100 training steps: 0.14206768968534753\n","Training loss per 100 training steps: 0.14122154206244844\n","Training loss per 100 training steps: 0.14038755296708846\n","Training loss per 100 training steps: 0.1395130018949772\n","Training loss per 100 training steps: 0.13852446422963113\n","Training loss per 100 training steps: 0.1377828447383043\n","Training loss per 100 training steps: 0.1369187770627102\n","Training loss per 100 training steps: 0.13628330405246272\n","Training loss per 100 training steps: 0.1357010742974261\n","Training loss per 100 training steps: 0.13503349350371807\n","Training loss per 100 training steps: 0.13465277435180462\n","Training loss per 100 training steps: 0.1340036976278876\n","Training loss per 100 training steps: 0.13348330599033906\n","Training loss per 100 training steps: 0.1327394579777777\n","Training loss per 100 training steps: 0.13241540845327182\n","Training loss per 100 training steps: 0.1318924536603121\n","Training loss per 100 training steps: 0.13139552091959253\n","Training loss per 100 training steps: 0.13090560712360205\n","Training loss per 100 training steps: 0.13022844391827174\n","Training loss per 100 training steps: 0.1297522092540093\n","Training loss per 100 training steps: 0.12932531857350424\n","Training loss per 100 training steps: 0.12892281399090055\n","Training loss per 100 training steps: 0.12840895066150407\n","Training loss per 100 training steps: 0.12780057503164682\n","Training loss per 100 training steps: 0.12721689641509434\n","Training loss per 100 training steps: 0.12671183848892692\n","Training loss per 100 training steps: 0.12619315507992165\n","Training loss per 100 training steps: 0.12575913352825058\n","Training loss per 100 training steps: 0.1252944730693093\n","Training loss per 100 training steps: 0.12490978894880242\n","Training loss per 100 training steps: 0.12456830919899825\n","Training loss per 100 training steps: 0.12414264563572996\n","Training loss per 100 training steps: 0.12367736764895283\n","Training loss per 100 training steps: 0.12329846290334909\n","Training loss per 100 training steps: 0.12282260634439565\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-d1e1c6555da2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training epoch: {epoch + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/baseline_checkpoint/model_weights_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-c3ae10999330>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"kv3PQZypdQ_t"},"source":["### 2) Evaluate the Model"]},{"cell_type":"code","metadata":{"id":"tGOfYsRn7Bj3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638516898429,"user_tz":-480,"elapsed":10078,"user":{"displayName":"haoqing tang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05592153470326549422"}},"outputId":"5dd51a2e-7ea3-4769-fe0d-3f2e351de59c"},"source":["model_1 = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(Ner_Tag))\n","model_1.load_state_dict(torch.load('/content/drive/MyDrive/baseline_checkpoint/model_weights_1.pth'))\n","model_1.to(device)\n","model_2 = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(Ner_Tag))\n","model_2.load_state_dict(torch.load('/content/drive/MyDrive/baseline_checkpoint/model_weights_2.pth'))\n","model_2.to(device)\n","model_3 = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(Ner_Tag))\n","model_3.load_state_dict(torch.load('/content/drive/MyDrive/baseline_checkpoint/model_weights_3.pth'))\n","model_3.to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",")"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"jFIfRvYXdQRv"},"source":["def valid(model_1,model_2,model_3, testing_loader):\n","    # put model in evaluation mode\n","    model_1.eval()\n","    model_2.eval()\n","    model_3.eval()\n","    eval_loss, eval_accuracy = 0, 0\n","    eval_loss_1, eval_accuracy_1 = 0, 0\n","    eval_loss_2, eval_accuracy_2 = 0, 0\n","    eval_loss_3, eval_accuracy_3 = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    eval_preds_1 = []\n","    eval_preds_2 = []\n","    eval_preds_3 = []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['labels'].to(device, dtype = torch.long)\n","\n","        #             outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n","        # loss = outputs[0]\n","        # tr_logits = outputs[1]\n","        # tr_loss += loss.item()\n","            \n","            outputs_1 = model_1(input_ids=ids, attention_mask=mask, labels=labels)\n","            loss_1 = outputs_1[0]\n","            eval_logits_1 = outputs_1[1]\n","            eval_loss_1 += loss_1.item()\n","\n","            outputs_2 = model_2(input_ids=ids, attention_mask=mask, labels=labels)\n","            loss_2 = outputs_2[0]\n","            eval_logits_2 = outputs_2[1]\n","            eval_loss_2 += loss_2.item()\n","\n","            outputs_3 = model_3(input_ids=ids, attention_mask=mask, labels=labels)\n","            loss_3 = outputs_3[0]\n","            eval_logits_3 = outputs_3[1]\n","            eval_loss_3 += loss_3.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            if idx % 100==0:\n","                loss_step_1 = eval_loss_1/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps for bert 1: {loss_step_1}\")\n","                loss_step_2 = eval_loss_2/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps for bert 2: {loss_step_2}\")\n","                loss_step_3 = eval_loss_3/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps for bert 3: {loss_step_3}\")\n","              \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits_1 = eval_logits_1.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions_1 = torch.argmax(active_logits_1, axis=1) # shape (batch_size * seq_len,)\n","            active_logits_2 = eval_logits_2.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions_2 = torch.argmax(active_logits_2, axis=1) # shape (batch_size * seq_len,)\n","            active_logits_3 = eval_logits_3.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions_3 = torch.argmax(active_logits_3, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions_1 = torch.masked_select(flattened_predictions_1, active_accuracy)\n","            predictions_2 = torch.masked_select(flattened_predictions_2, active_accuracy)\n","            predictions_3 = torch.masked_select(flattened_predictions_3, active_accuracy)\n","            \n","            #ensemble_Fusion of three Bert results\n","            length = len(labels)\n","            num = np.zeros((length,9),dtype=int)\n","            predictions = []\n","            for i in range(0,length):\n","              val_1 = predictions_1[i]\n","              val_2 = predictions_2[i]\n","              val_3 = predictions_3[i]\n","              num[i][val_1] += 1\n","              num[i][val_2] += 1\n","              num[i][val_3] += 1\n","            \n","            for i in range(0,length):\n","              flag = 0\n","              for j in range(0,9):\n","                if num[i][j] >= 2:\n","                  predictions.append(j)\n","                  flag = 1\n","              if flag == 0:\n","                max_1 = torch.max(active_logits_1[i],0)[0]\n","                maxNo_1 = torch.max(active_logits_1[i],0)[1]\n","                maxNo_1 = int(maxNo_1)\n","                max_2 = torch.max(active_logits_2[i],0)[0]\n","                maxNo_2 = torch.max(active_logits_2[i],0)[1]\n","                maxNo_2 = int(maxNo_2)\n","                max_3 = torch.max(active_logits_3[i],0)[0]\n","                maxNo_3 = torch.max(active_logits_3[i],0)[1]\n","                maxNo_3 = int(maxNo_3)   \n","                if torch.gt(max_1,max_2):\n","                  if torch.gt(max_1,max_3):\n","                    predictions.append(maxNo_1)\n","                  else:\n","                    predictions.append(maxNo_3)\n","                else:\n","                  if torch.gt(max_2,max_3):\n","                    predictions.append(maxNo_2)\n","                  else:\n","                    predictions.append(maxNo_3)\n","                    \n","\n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            eval_preds_1.extend(predictions_1)\n","            eval_preds_2.extend(predictions_2)\n","            eval_preds_3.extend(predictions_3)\n","\n","            #predictions_tensor = torch.tensor(predictions).to(device)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), torch.tensor(predictions).cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","            tem_eval_accuracy_1 = accuracy_score(labels.cpu().numpy(),predictions_1.cpu().numpy())\n","            eval_accuracy_1 += tem_eval_accuracy_1\n","            tem_eval_accuracy_2 = accuracy_score(labels.cpu().numpy(),predictions_2.cpu().numpy())\n","            eval_accuracy_2 += tem_eval_accuracy_2\n","            tem_eval_accuracy_3 = accuracy_score(labels.cpu().numpy(),predictions_3.cpu().numpy())\n","            eval_accuracy_3 += tem_eval_accuracy_3\n","\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    eval_accuracy_1 = eval_accuracy_1 / nb_eval_steps\n","    eval_accuracy_2 = eval_accuracy_2 / nb_eval_steps\n","    eval_accuracy_3 = eval_accuracy_3 / nb_eval_steps\n","\n","    print(f\"Validation Accuracy of epoch 1: {eval_accuracy_1}\")\n","    print(f\"Validation Accuracy of epoch 2: {eval_accuracy_2}\")\n","    print(f\"Validation Accuracy of epoch 3: {eval_accuracy_3}\")\n","\n","    return eval_labels, eval_preds\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8sIjYU32Z2J","executionInfo":{"status":"ok","timestamp":1638520126166,"user_tz":-480,"elapsed":562126,"user":{"displayName":"haoqing tang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05592153470326549422"}},"outputId":"5d947856-da92-4bdd-faf4-0cfa1e0bab17"},"source":["labels, predictions = valid(model_1,model_2,model_3,testing_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation loss per 100 evaluation steps for bert 1: 0.0005527503089979291\n","Validation loss per 100 evaluation steps for bert 2: 0.00018127560906577855\n","Validation loss per 100 evaluation steps for bert 3: 0.0001076681146514602\n","Validation loss per 100 evaluation steps for bert 1: 0.12272651051228756\n","Validation loss per 100 evaluation steps for bert 2: 0.14219734729005434\n","Validation loss per 100 evaluation steps for bert 3: 0.15099737038286945\n","Validation loss per 100 evaluation steps for bert 1: 0.13761617202805215\n","Validation loss per 100 evaluation steps for bert 2: 0.13794038675698528\n","Validation loss per 100 evaluation steps for bert 3: 0.17454892652298512\n","Validation loss per 100 evaluation steps for bert 1: 0.13316019640193535\n","Validation loss per 100 evaluation steps for bert 2: 0.13849709209910807\n","Validation loss per 100 evaluation steps for bert 3: 0.1677743196671864\n","Validation loss per 100 evaluation steps for bert 1: 0.15432354984828212\n","Validation loss per 100 evaluation steps for bert 2: 0.1631408930568392\n","Validation loss per 100 evaluation steps for bert 3: 0.1989835419934256\n","Validation loss per 100 evaluation steps for bert 1: 0.1393509192819551\n","Validation loss per 100 evaluation steps for bert 2: 0.145801900757588\n","Validation loss per 100 evaluation steps for bert 3: 0.1750262740997514\n","Validation loss per 100 evaluation steps for bert 1: 0.13088747977479415\n","Validation loss per 100 evaluation steps for bert 2: 0.14006465069639024\n","Validation loss per 100 evaluation steps for bert 3: 0.1651213357706097\n","Validation loss per 100 evaluation steps for bert 1: 0.1292072126243965\n","Validation loss per 100 evaluation steps for bert 2: 0.14193455582472064\n","Validation loss per 100 evaluation steps for bert 3: 0.16365443735144766\n","Validation loss per 100 evaluation steps for bert 1: 0.12676800963801382\n","Validation loss per 100 evaluation steps for bert 2: 0.14032597350504628\n","Validation loss per 100 evaluation steps for bert 3: 0.1622835523186732\n","Validation loss per 100 evaluation steps for bert 1: 0.1261649432357713\n","Validation loss per 100 evaluation steps for bert 2: 0.1385612264037649\n","Validation loss per 100 evaluation steps for bert 3: 0.1609573163228837\n","Validation loss per 100 evaluation steps for bert 1: 0.12425837451096654\n","Validation loss per 100 evaluation steps for bert 2: 0.13493790644308873\n","Validation loss per 100 evaluation steps for bert 3: 0.15783380325089597\n","Validation loss per 100 evaluation steps for bert 1: 0.11877446823934648\n","Validation loss per 100 evaluation steps for bert 2: 0.12877380377356862\n","Validation loss per 100 evaluation steps for bert 3: 0.15175006309224734\n","Validation loss per 100 evaluation steps for bert 1: 0.11860790088484692\n","Validation loss per 100 evaluation steps for bert 2: 0.12825405667327558\n","Validation loss per 100 evaluation steps for bert 3: 0.1513200004272094\n","Validation loss per 100 evaluation steps for bert 1: 0.11583072299162409\n","Validation loss per 100 evaluation steps for bert 2: 0.12611930745076966\n","Validation loss per 100 evaluation steps for bert 3: 0.14771734706061412\n","Validation loss per 100 evaluation steps for bert 1: 0.11346628397821497\n","Validation loss per 100 evaluation steps for bert 2: 0.12253729394996805\n","Validation loss per 100 evaluation steps for bert 3: 0.1429733482982426\n","Validation loss per 100 evaluation steps for bert 1: 0.11377525803584793\n","Validation loss per 100 evaluation steps for bert 2: 0.12342030866253108\n","Validation loss per 100 evaluation steps for bert 3: 0.14410386423565885\n","Validation loss per 100 evaluation steps for bert 1: 0.11191453364943715\n","Validation loss per 100 evaluation steps for bert 2: 0.12040952494641399\n","Validation loss per 100 evaluation steps for bert 3: 0.14114112444650442\n","Validation loss per 100 evaluation steps for bert 1: 0.11151240045738038\n","Validation loss per 100 evaluation steps for bert 2: 0.12083111680301843\n","Validation loss per 100 evaluation steps for bert 3: 0.14047162691586698\n","Validation Loss: 0.0\n","Validation Accuracy: 0.9752313445360107\n","Validation Accuracy of epoch 1: 0.9730354916918441\n","Validation Accuracy of epoch 2: 0.9742576055448429\n","Validation Accuracy of epoch 3: 0.9741218279520122\n"]}]},{"cell_type":"code","metadata":{"id":"c7ArcZ0wusBi"},"source":["len(testing_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6eqElS_5v-e"},"source":["model.load_state_dict(torch.load('/content/drive/MyDrive/NLP/Final Project/Code/Baseline/Baseline Saved Model/pytorch_model.bin'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZJN32jfGd3sQ"},"source":[" labels, predictions = valid(model, testing_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-j7ltuGjWAB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638520361792,"user_tz":-480,"elapsed":264,"user":{"displayName":"haoqing tang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05592153470326549422"}},"outputId":"7ed450a0-0106-4665-aaa2-39acafc6e708"},"source":["New_NerDict = dict((v,k) for k,v in dict(Ner).items())\n","New_NerDict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'O',\n"," 1: 'B-PER',\n"," 2: 'I-PER',\n"," 3: 'B-ORG',\n"," 4: 'I-ORG',\n"," 5: 'B-LOC',\n"," 6: 'I-LOC',\n"," 7: 'B-MISC',\n"," 8: 'I-MISC'}"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"WUkwANjxkP2q","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"error","timestamp":1638520558239,"user_tz":-480,"elapsed":1027,"user":{"displayName":"haoqing tang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05592153470326549422"}},"outputId":"d21244ba-443f-4bbe-89f7-9c65b420e7b4"},"source":["from sklearn.metrics import classification_report\n","\n","labels_value = [[New_NerDict[i.item()] for i in labels]]\n","pred_value = [[New_NerDict[i] for i in predictions]]\n","\n","print(classification_report(labels_value, pred_value))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-100-bc3f00ae343e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNew_NerDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \"\"\"\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2076\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: multiclass-multioutput is not supported"]}]},{"cell_type":"code","metadata":{"id":"CdHNOEf5d7Sf"},"source":["from seqeval.metrics import classification_report\n","\n","print(classification_report(labels_value, pred_value))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tLT4WtJ_MS3F"},"source":["### 3) Save Model"]},{"cell_type":"code","metadata":{"id":"oq6073uHMWsu"},"source":["import os\n","\n","directory = \"./model\"\n","\n","if not os.path.exists(directory):\n","    os.makedirs(directory)\n","\n","# save vocabulary of the tokenizer\n","tokenizer.save_vocabulary(directory)\n","# save the model weights and its configuration file\n","model.save_pretrained(directory)\n","print('All files saved')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qT66WzNhmGTT"},"source":["#torch.save(model, 'model.pth')\n","\n","#torch.save(model.state_dict(), 'model_weights.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"101dcJ0w5rKK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638621084503,"user_tz":-480,"elapsed":23650,"user":{"displayName":"Xuanjin JI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgH0VUB3HpvI_MX3OiKITS606e9ji6IlLVLHhb9Hg=s64","userId":"14027953670718372733"}},"outputId":"667af2c9-b2da-453d-ecda-2d165c8bcd90"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}]}